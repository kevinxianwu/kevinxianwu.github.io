% Encoding: UTF-8


@InProceedings{shi2021proximal,
  author    = {Wenxian Shi and Yuxuan Song and Bohan Li and Hao Zhou and Lei Li},
  booktitle = {ECML-PKDD},
  title     = {Proximal Knowledge Teaching for Neural Networks},
  year      = {2021},
  month     = sep,
}

@InProceedings{ye2021end,
  author    = {Rong Ye and Mingxuan Wang and Lei Li},
  booktitle = {Proc. of INTERSPEECH},
  title     = {End-to-end Speech Translation via Cross-modal Progressive Training},
  year      = {2021},
  month     = aug,
  eprint    = {https://arxiv.org/abs/2104.10380},
}

@InProceedings{lin2021learning,
  author    = {Zehui Lin and Liwei Wu and Mingxuan Wang and Lei Li},
  booktitle = {the 59th Annual Meeting of the Association for Computational Linguistics (ACL)},
  title     = {Learning Language Specific Sub-network for Multilingual Machine Translation},
  year      = {2021},
  month     = aug,
  abstract  = {Multilingual neural machine translation aimsat learning a single translation model for muliple  languages.  These  jointly  trained  mod-els often suffer from performance degradationon rich-resource language pairs. We attributethis degeneration to parameter interference. Inthis paper, we propose LaSS to jointly train asingle  unified  multilingual  MT  model.  LaSS learns Language Secific Sub-network (LaSS)for  each  language  pair  to  counter  parameterinterference.  Comprehensive  experiments  on IWSLT and WMT datasets with various Transformer  architectures  show  that  LaSS  obtainsgains on 36 language pairs by up to 1.2 BLEU.Besides, LaSS shows its strong generalization performance  at  easy  adaptation  to  new  lan-guage  pairs  and  zero-shot  translation.  LaSS boosts  zero-shot  translation  with  an  averageof  8.3  BLEU  on  30  language  pairs.},
  code      = {https://github.com/NLP-Playground/LaSS},
  eprint    = {https://arxiv.org/abs/2105.09259},
  timestamp = {2020-05-01},
}

@InProceedings{hua2020xref,
  author    = {Xinyu Hua and Lei Li and Lifeng Hua and Lu Wang},
  booktitle = {Automated Knowledge Base Construction (AKBC)},
  title     = {{XREF}: Entity Linking for {Chinese} News Comments with Supplementary Article Reference},
  year      = {2020},
  month     = jun,
  abstract  = {Automatic identification of mentioned entities in social media posts facilitates quick digestion of trending topics and popular opinions. Nonetheless, this remains a challenging task due to limited context and diverse name variations. In this paper, we study the problem of entity linking for Chinese news comments given mentionsâ€™ spans. We hypothesize that comments often refer to entities in the corresponding news article, as well as topics involving the entities. We therefore propose a novel model, XREF, that leverages attention mechanisms to (1) pinpoint relevant context within comments, and (2) detect supporting entities from the news article. To improve training, we make two contributions: (a) we propose a supervised attention loss in addition to the standard cross entropy, and (b) we develop a weakly supervised training scheme to utilize the large-scale unlabeled corpus. Two new datasets in entertainment and product domains are collected and annotated for experiments. Our proposed method outperforms previous methods on both datasets.},
  url       = {https://xinyuhua.github.io/Resources/akbc20/},
}

@Article{kong2020foveabox,
  author   = {Tao {Kong} and Fuchun {Sun} and Huaping {Liu} and Yuning {Jiang} and Lei {Li} and Jianbo {Shi}},
  journal  = {IEEE Transactions on Image Processing},
  title    = {{FoveaBox}: Beyound Anchor-based Object Detection},
  year     = {2020},
  issn     = {1057-7149},
  month    = jun,
  pages    = {7389-7398},
  volume   = {29},
  abstract = {We present FoveaBox, an accurate, flexible, and completely anchor-free framework for object detection. While almost all state-of-the-art object detectors utilize predefined anchors to enumerate possible locations, scales and aspect ratios for the search of the objects, their performance and generalization ability are also limited to the design of anchors. Instead, FoveaBox directly learns the object existing possibility and the bounding box coordinates without anchor reference. This is achieved by: (a) predicting category-sensitive semantic maps for the object existing possibility, and (b) producing category-agnostic bounding box for each position that potentially contains an object. The scales of target boxes are naturally associated with feature pyramid representations. In FoveaBox, an instance is assigned to adjacent feature levels to make the model more accurate.We demonstrate its effectiveness on standard benchmarks and report extensive experimental analysis. Without bells and whistles, FoveaBox achieves state-of-the-art single model performance on the standard COCO and Pascal VOC object detection benchmark. More importantly, FoveaBox avoids all computation and hyper-parameters related to anchor boxes, which are often sensitive to the final detection performance. We believe the simple and effective approach will serve as a solid baseline and help ease future research for object detection. The code has been made publicly available at https://github.com/taokong/FoveaBox.},
  code     = {https://github.com/taokong/FoveaBox},
  doi      = {https://doi.org/10.1109/TIP.2020.3002345},
  eprint   = {https://arxiv.org/abs/1904.03797},
  url      = {http://www.taokong.org/projects/FoveaBox/},
}

@Article{wu2020towards,
  author  = {Wu, Fei and Lu, Cewu and Zhu, Mingjie and Chen, Hao and Zhu, Jun and Yu, Kai and Li, Lei and Li, Ming and Chen, Qianfeng and Li, Xi and Cao, Xudong and Wang, Zhongyuan and Zha, Zhengjun and Zhuang, Yueting and Pan, Yunhe},
  journal = {Nature Machine Intelligence},
  title   = {Towards a new generation of artificial intelligence in {China}},
  year    = {2020},
  month   = jun,
  pages   = {312-316},
  volume  = {2},
  doi     = {https://doi.org/10.1038/s42256-020-0183-4},
  eprint  = {https://rdcu.be/b5vk7},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: fileDirectory:./;}

@Comment{jabref-meta: saveOrderConfig:specified;year;true;month;true;booktitle;false;}
